{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "from email_config import *\n",
    "from news_config import *\n",
    "from st_email import sendEmail\n",
    "from st_summarizer import summarize\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import fulltext\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from urllib import request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'email_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec2e23ff4944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0memail_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnews_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mst_email\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msendEmail\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'email_config'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STRAITS TIMES SUMMARIZER\n",
    "Author: ahthon\n",
    "Date created: 14 Oct 2017\n",
    "Date last modified: 01 Sep 2018\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "st_summarizer = \"\"\"\n",
    "       ______           _ __        _______\n",
    "      / __/ /________ _(_) /____   /_  __(_)_ _  ___ ___\n",
    "     _\\ \\/ __/ __/ _ `/ / __(_-<    / / / /  ' \\/ -_|_-<\n",
    "    /___/\\__/_/  \\_,_/_/\\__/___/   /_/ /_/_/_/_/\\__/___/\n",
    "       _  __                 ____                          _\n",
    "      / |/ /__ _    _____   / __/_ ____ _  __ _  ___ _____(_)__ ___ ____\n",
    "     /    / -_) |/|/ (_-<  _\\ \\/ // /  ' \\/  ' \\/ _ `/ __/ /_ // -_) __/\n",
    "    /_/|_/\\__/|__,__/___/ /___/\\_,_/_/_/_/_/_/_/\\_,_/_/ /_//__/\\__/_/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def articleHTML(url):\n",
    "    \"\"\"Returns html soup.\n",
    "    \"\"\"\n",
    "    html = request.urlopen(url).read().decode(\"utf8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    return(soup)\n",
    "\n",
    "\n",
    "def articleURLs(soup, url_count):\n",
    "    \"\"\"Returns article urls of a certain news category.\n",
    "    \"\"\"\n",
    "    st = \"http://www.straitstimes.com\"\n",
    "    hrefs = str(soup.find_all(\n",
    "        \"span\", class_=\"story-headline\", limit=url_count))\n",
    "    urls = re.findall('href=\\\"(.*?)\\\"', hrefs)\n",
    "    urls = [st+url for url in urls if urls and \"javascript\" not in url]\n",
    "    urls = [url for url in urls if \"multimedia/\" not in url]\n",
    "    return(urls)\n",
    "\n",
    "\n",
    "def urlCategory(url):\n",
    "    \"\"\"Returns an article's category from its url.\n",
    "    \"\"\"\n",
    "    pattern = \"straitstimes.com/(\\w*)/\"\n",
    "    cat = re.search(pattern, url)\n",
    "    if cat:\n",
    "        cat = cat.group(1).title()\n",
    "        return(cat)\n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "\n",
    "def urlSubCategory(url):\n",
    "    \"\"\"Returns an article's subcategory from its url.\n",
    "    \"\"\"\n",
    "    pattern = \"straitstimes.com/\\w*/([a-z-].*)/\"\n",
    "    subcat = re.search(pattern, url)\n",
    "    if subcat:\n",
    "        subcat = subcat.group(1).title()\n",
    "        if subcat == \"Australianz\":\n",
    "            subcat = \"Australia-NZ\"\n",
    "        elif subcat == \"Se-Asia\":\n",
    "            subcat = \"SE-Asia\"\n",
    "        return(subcat)\n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "\n",
    "def articleTitle(soup):\n",
    "    \"\"\"Returns news title.\n",
    "    \"\"\"\n",
    "    title = soup.find(\"h1\", class_=\"headline node-title\")\n",
    "    title = title.string\n",
    "    return(title)\n",
    "\n",
    "\n",
    "def articleByline(soup):\n",
    "    \"\"\"Returns news byline/author. Returns '--' if none is found.\n",
    "    \"\"\"\n",
    "    author = soup.find(\"div\", class_=\"author-field author-name\")\n",
    "    designation = soup.find(\"div\", class_=\"author-designation author-field\")\n",
    "\n",
    "    if author and designation:\n",
    "        author = str(author.string)\n",
    "        designation = str(designation.string)                     \n",
    "        return(author+\" | \"+designation)\n",
    "    elif author:\n",
    "        author = str(author.string)\n",
    "        return(author)\n",
    "    else:\n",
    "        return(\"--\")\n",
    "\n",
    "\n",
    "def articleText(url):\n",
    "    \"\"\"Returns news text.\n",
    "    \"\"\"\n",
    "    html = requests.get(url).text\n",
    "    text = fulltext(html)\n",
    "    return(text)\n",
    "\n",
    "\n",
    "def articleJavaScript(soup):\n",
    "    \"\"\"Returns article's html (script tag).\n",
    "    \"\"\"\n",
    "    script = str(soup.find_all(\"script\"))\n",
    "    return(script)\n",
    "\n",
    "\n",
    "def articleID(js):\n",
    "    \"\"\" Returns art ID.\n",
    "    \"\"\"\n",
    "    target = '\"articleid\".*\"(\\d*)\"'\n",
    "    pub_id = re.search(target, js)\n",
    "    if pub_id:\n",
    "        return(pub_id.group(1))\n",
    "\n",
    "\n",
    "def articleDateTime(js):\n",
    "    \"\"\"Returns publication date and time (yyyy:mm:dd hh:mm) of news.\n",
    "    \"\"\"\n",
    "    target = '\"pubdate\":\"(.*)\"'\n",
    "    pubdate = re.search(target, js)\n",
    "    if pubdate:\n",
    "        return(pubdate.group(1).split(\" \"))\n",
    "\n",
    "\n",
    "def articleDate(pub_datetime):\n",
    "    \"\"\"Returns article's published datetime.\n",
    "    \"\"\"\n",
    "    pubdate = pub_datetime[0]\n",
    "    date = pubdate.split(\"-\")\n",
    "\n",
    "    year, month, day = date[0], date[1], date[2]\n",
    "\n",
    "    months = {\n",
    "        \"01\": \"Jan\", \"02\": \"Feb\", \"03\": \"Mar\", \"04\": \"Apr\",\n",
    "        \"05\": \"May\", \"06\": \"Jun\", \"07\": \"Jul\", \"08\": \"Aug\",\n",
    "        \"09\": \"Oct\", \"10\": \"Sep\", \"11\": \"Nov\", \"12\": \"Dec\"}\n",
    "\n",
    "    month_name = months.get(month)\n",
    "    pub_date = \"{} {} {}\".format(day, month_name, year)\n",
    "    return(pub_date)\n",
    "\n",
    "\n",
    "def articleTime(pub_datetime):\n",
    "    \"\"\"Returns article's published time.\n",
    "    \"\"\"\n",
    "    pubtime = pub_datetime[1]\n",
    "    pub_time = pubtime + \" Hours\"\n",
    "    return(pub_time)\n",
    "\n",
    "\n",
    "def articleKeywords(js):\n",
    "    \"\"\"Returns a list of news topics/tags.\n",
    "    \"\"\"\n",
    "    target = '\"keyword\".*\"(.*)\"'\n",
    "    keyword = re.search(target, js)\n",
    "    if keyword:\n",
    "        keywords = keyword.group(1).split(\",\")\n",
    "    return(keywords)\n",
    "\n",
    "\n",
    "def write(text, file, linebreak=True):\n",
    "    \"\"\"Prints to file some text.\n",
    "    \"\"\"\n",
    "    print(text, file=file)\n",
    "\n",
    "    # print new, empty line\n",
    "    if linebreak is True:\n",
    "        print(\"\", file=file)\n",
    "\n",
    "\n",
    "def writeDivider(file):\n",
    "    \"\"\"Prints fancy divider.\n",
    "    \"\"\"\n",
    "    write(\"***\", file)\n",
    "\n",
    "\n",
    "def wordCount(text):\n",
    "    \"\"\"Returns word count.\n",
    "    \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r\"\\w(?:[-\\w]*\\w)?\")\n",
    "    count = len(tokenizer.tokenize(text))\n",
    "    return(count)\n",
    "\n",
    "\n",
    "def sentCount(text):\n",
    "    \"\"\"Returns sentence count.\n",
    "    \"\"\"\n",
    "    count = len(sent_tokenize(text))\n",
    "    return(count)\n",
    "\n",
    "\n",
    "def Main(percent_reduce, todays_news, email_news):\n",
    "\n",
    "    date_today = time.strftime(\"%d %b %Y\")  # dd mmm yyyy\n",
    "    print(st_summarizer)\n",
    "    print(\"  Collecting news for {}.\\n\".format(date_today))\n",
    "\n",
    "    # statistics and counters\n",
    "    reduction = []\n",
    "    summarized = 0\n",
    "    articles_fetched = 0\n",
    "\n",
    "    # news categories\n",
    "    print(\"  Categories fetched: {}\".format(len(st_categories)))\n",
    "    for (cat, cat_url, filename) in st_categories:\n",
    "        print(\"\\t[{}]\".format(cat))\n",
    "\n",
    "    # urls of articles for each category\n",
    "    st_cats_urls = []\n",
    "    for (cat, cat_url, filename) in st_categories:\n",
    "        urls = articleURLs(articleHTML(cat_url), headline_count)\n",
    "        st_cats_urls.append((urls, cat, filename))\n",
    "        articles_fetched += len(urls)\n",
    "    print(\"\\n  Articles fetched: {}\\n\".format(articles_fetched))\n",
    "\n",
    "    st_articles = [urls for urls in st_cats_urls]\n",
    "\n",
    "    with open(\"ST_News-Headlines.txt\", \"w\", encoding=\"utf8\") as email_file:\n",
    "        print(\"  Summarizing articles...\\n\")\n",
    "        write(\n",
    "            \"News headlines on {}\\n\".format(date_today),\n",
    "            email_file)\n",
    "\n",
    "        # look at each news category\n",
    "        for (urls, cat, filename) in st_articles:\n",
    "            print(\"  \"+cat.upper())\n",
    "            cat_title = \"\\n{}\\n{}\".format(cat.upper(), \"=\"*len(cat))\n",
    "\n",
    "            summary_filename = \"s_\"+filename\n",
    "            news_filename = \"o_\"+filename\n",
    "\n",
    "            with open(summary_filename, \"w\", encoding=\"utf8\") as summ_file:\n",
    "                with open(news_filename, \"w\", encoding=\"utf8\") as news_file:\n",
    "                    write(cat_title, summ_file)\n",
    "                    write(cat_title, news_file)\n",
    "                    write(cat_title, email_file, linebreak=False)\n",
    "\n",
    "                    article_count = 0\n",
    "\n",
    "                    for url in urls:\n",
    "\n",
    "                        # word count\n",
    "                        wordcount_summ = 0\n",
    "                        wordcount_news = 0\n",
    "\n",
    "                        # article data\n",
    "                        html = articleHTML(url)\n",
    "                        js = articleJavaScript(html)\n",
    "                        pub_datetime = articleDateTime(js)\n",
    "                        pub_date = articleDate(pub_datetime)\n",
    "                        pub_time = articleTime(pub_datetime)\n",
    "\n",
    "                        if todays_news is True and pub_date != date_today:\n",
    "                            # skip to next article if it's not published today\n",
    "                            continue\n",
    "                        else:\n",
    "                            article_count += 1\n",
    "                            cat_in_url = urlCategory(url)\n",
    "                            subcat_in_url = urlSubCategory(url)\n",
    "\n",
    "                            # get news subcategory;\n",
    "                            # otherwise, get main category\n",
    "                            if subcat_in_url is None:\n",
    "                                subcat_in_url = cat_in_url\n",
    "\n",
    "                        pub_id = \"#{}\".format(articleID(js))\n",
    "                        title = pub_id+\" \"+articleTitle(html)\n",
    "                        byline = articleByline(html)\n",
    "                        keywords = articleKeywords(js)\n",
    "                        text = articleText(url)\n",
    "                        wordcount_news += wordCount(text)\n",
    "\n",
    "                        print(\n",
    "                            \"\\t{:02d}.\".format(article_count),\n",
    "                            \"[{}]{}\".format(pub_date, title[len(pub_id):])\n",
    "                        )\n",
    "\n",
    "                        # output, news headlines\n",
    "                        write(\"[{}] {}\\n{}\".format(\n",
    "                            pub_date, title, url),\n",
    "                            email_file\n",
    "                        )\n",
    "\n",
    "                        # output, news summary\n",
    "                        write(title, summ_file)\n",
    "                        write(url, summ_file)\n",
    "                        write(\"By: \"+byline, summ_file)\n",
    "                        write(pub_date+\", \"+pub_time, summ_file)\n",
    "\n",
    "                        # length of summary\n",
    "                        sents_in_summary = int(\n",
    "                            percent_reduce*sentCount(text)\n",
    "                            )\n",
    "\n",
    "                        # summarized text\n",
    "                        summary = summarize(url, sents_in_summary)\n",
    "                        news_lead = sent_tokenize(text)[0]\n",
    "                        if news_lead not in summary[0:1]:  # includes lead\n",
    "                            write(news_lead, summ_file)\n",
    "                            wordcount_summ += wordCount(news_lead)\n",
    "                        for sent in summary:\n",
    "                            write(sent, summ_file)\n",
    "                            wordcount_summ += wordCount(sent)\n",
    "\n",
    "                        write(keywords, summ_file)\n",
    "                        writeDivider(summ_file)\n",
    "                        summarized += 1\n",
    "\n",
    "                        # output, original news arts\n",
    "                        write(title+\" [{}]\".format(subcat_in_url), news_file)\n",
    "                        write(url, news_file)\n",
    "                        write(\"By: \"+byline, news_file)\n",
    "                        write(pub_date+\", \"+pub_time, news_file)\n",
    "                        write(text, news_file)\n",
    "                        write(keywords, news_file)\n",
    "                        writeDivider(news_file)\n",
    "\n",
    "                        # reduction in words\n",
    "                        reduction.append(\n",
    "                            (wordcount_news-wordcount_summ)/wordcount_news\n",
    "                            )\n",
    "                    writeDivider(email_file)\n",
    "\n",
    "                    if article_count == 0:  # no news for today\n",
    "                        print(\n",
    "                            \"\\t{:02d}.\".format(article_count),\n",
    "                            \"[{}] [No Updates]\".format(date_today)\n",
    "                        )\n",
    "                    print(\"\")\n",
    "\n",
    "    mean_reduction = statistics.mean(reduction)\n",
    "    stdev_reduction = statistics.stdev(reduction)\n",
    "    print(\"  Articles summarized: {}\".format(summarized))\n",
    "    print(\"  Avg. word reduction: {:.1f}%, SD: {:.2f}\\n\".format(\n",
    "        (mean_reduction*100), stdev_reduction))\n",
    "\n",
    "    if email_news is True:\n",
    "        sendEmail(gmail_user, gmail_pwd, send_to)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Main(percent_reduce, todays_news, email_news)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
