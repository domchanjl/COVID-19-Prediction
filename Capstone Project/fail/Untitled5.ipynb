{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "### Use either Firefox or Chrome to load the webpages\n",
    "#browser = webdriver.Firefox()\n",
    "browser = webdriver.Chrome(\"C:/Users/domin/Desktop/chromedriver.exe\")\n",
    "\n",
    "### URL to scrap\n",
    "url = \"https://twitter.com/smrt_singapore?lang=en\"\n",
    "\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Selenium script to auto scroll to the end of page, with interval of 3 seconds between scroll.\n",
    "### For purpose of testing, skip this part of code.\n",
    "\n",
    "#from selenium import webdriver\n",
    "#browser = webdriver.Firefox()\n",
    "#browser.get(\"https://twitter.com/smrt_singapore?lang=en\")\n",
    "lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight); \\\n",
    "                                var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "match=False\n",
    "while(match==False):\n",
    "    lastCount = lenOfPage\n",
    "    time.sleep(3)    # pause for 3 seconds before next scroll\n",
    "    lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\\\n",
    "                                var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "    if lastCount==lenOfPage:\n",
    "        match=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scrap the HTML after fully load the web page and load into BeautifulSoup.\n",
    "\n",
    "source_data = browser.page_source\n",
    "bs_data = bs(source_data, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Verify data extraction for one tweet is correct.\n",
    "\n",
    "article_info = bs_data.find(\"p\", {\"class\": 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text'})\n",
    "print(article_info.text)\n",
    "\n",
    "article_info = bs_data.find('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip' })['title']\n",
    "print (article_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Verify REGEX pattern extracts correctly\n",
    "\n",
    "import re\n",
    "\n",
    "# Sample tweet\n",
    "s = '[NSL] CLEARED: Train svc from #YewTee to #JurongEast is running normally now.'\n",
    "\n",
    "repatt = r'[\\bbetween\\b|\\bbtwn\\b|\\bfrom\\b] \\#(\\w*)[\\s\\w]*[and|to|&]*[\\s]*\\#[\\s]*(\\w*)'\n",
    "#repatt = r\"\\bCLEARED\\b|\\bcleared\\b|\\bCleared\\b|\\bhave resume\\b|\\bhave resumed\\b|\\bhas resumed\\b|\\bservice resumed\\b|\\bnormal\\b|\\bnormally\\b|\\bceased\\b|\\bcease\\b\"    # indication that fault is cleared or services is resumed\n",
    "#repatt = r'\\bEWL\\b|\\bNSL\\b|\\bCCL\\b'\n",
    "#repatt  = r'[F|f][ree][\\w\\s\\d\\&\\#]*end'\n",
    "\n",
    "extract = re.search(repatt, s)\n",
    "if extract:  \n",
    "    print (\"From: %s  To: %s\\n\" % (extract.group(1), extract.group(2))) \n",
    "    #print (extract.group(0))\n",
    "else:\n",
    "    print(\"Extraction Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Actual script to extract all the relevant data (tweets, date/time, Station Names, MRT Status)\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "article_infoAll = bs_data.find_all(\"div\", {\"class\": 'content'})\n",
    "\n",
    "smrt_tweet_data = []  # list container to hold all extracted SMRT tweet\n",
    "\n",
    "### Regex extraction pattern\n",
    "### ========================\n",
    "re_mrtline = r'^[\\[]*(\\bNSL\\b|\\bEWL\\b|\\bCCL\\b|\\bBPLRT\\b|\\bDTL\\b)'\n",
    "re_mrtstatus = r'\\bCLEARED\\b|\\bcleared\\b|\\bCleared\\b|\\bhave resume\\b|\\bhave resumed\\b|\\bhas resumed\\b|\\bservice resumed\\b|\\bnormal\\b|\\bnormally\\b|\\bceased\\b|\\bcease\\b'    # indication that fault is cleared or services is resumed\n",
    "re_patt = r'[F|f][ree][\\w\\s\\d\\&\\#]*ended'\n",
    "re_stn = r'[\\bbetween\\b|\\bbtwn\\b|\\bfrom\\b] \\#(\\w*)[\\s\\w]*[and|to|&]*[\\s]*\\#[\\s]*(\\w*)'\n",
    "\n",
    "for item in article_infoAll:\n",
    "    \n",
    "    tweet_row = [] # list container to hold extracted tweet info for each SMRT tweet\n",
    "    \n",
    "    try:\n",
    "\n",
    "        ### Extract tweet body from html\n",
    "        ### ============================\n",
    "        tweet_body = item.find(\"p\", {\"class\": 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text'})\n",
    "        tweet_row.append(tweet_body.text)\n",
    "\n",
    "        ### Extract date and time from the html\n",
    "        ### ===================================\n",
    "        tweet_datetime = item.find('a', {'class': 'tweet-timestamp js-permalink js-nav js-tooltip' })['title']\n",
    "        tweet_row.append(tweet_datetime)\n",
    "        \n",
    "        ### Convert extract tweet_datetime into datetime object so that it can be calculated\n",
    "        ### =======================================\n",
    "        date = datetime.strptime(tweet_datetime, '%I:%M %p - %d %b %Y')\n",
    "        print(\"Converted date/time: %s\" % date)\n",
    "        tweet_row.append(date)        \n",
    "        \n",
    "        ### ================================================================================\n",
    "        ### If tweet starts with [xxx], it indicate the tweet had MRT status information\n",
    "        ### Extract tweet using regex to determine status type, i.e.'cleared', 'update', 'ok'\n",
    "        ### ================================================================================\n",
    "        \n",
    "        ### Extract and check if tweet starts with [xxx]\n",
    "        ### ============================================\n",
    "        mrtline = re.search(re_mrtline, tweet_body.text)\n",
    "        \n",
    "        if mrtline:  # if the tweet starts with [XXX], then it is a status tweet\n",
    "            ### Extract MRT Line inside []\n",
    "            ### ==========================\n",
    "            print(\"Extracted MRT Line: \" + mrtline.group(1))\n",
    "            tweet_row.append(mrtline.group(1))\n",
    "            \n",
    "            ### Extract MRT Line status based on keywords\n",
    "            ### =========================================\n",
    "            mrtstatus = re.search(re_mrtstatus, tweet_body.text)\n",
    "            if mrtstatus:   # if is status is stated 'cleared' in tweeter\n",
    "                print(\"Status: Cleared\") \n",
    "                print(\"Extracted tweet: %s\\n\" % tweet_body.text)\n",
    "                tweet_row.append('cleared')\n",
    "            else:\n",
    "                patt=re.search(re_patt, tweet_body.text)\n",
    "                if patt:    # check if there are other indicators that inferred as 'cleared'. Such as 'Free ... ended'.\n",
    "                    print(\"Status: Cleared\") \n",
    "                    print(\"Extracted tweet: %s\\n\" % tweet_body.text)\n",
    "                    tweet_row.append('cleared')\n",
    "                else:       # if is a status tweet but no 'cleared' status, then the tweet will be a disruption status.\n",
    "                    print(\"Status: Update\")\n",
    "                    print(\"Extracted tweet: %s\" % tweet_body.text.replace('\\n','')) # some tweet has newline\n",
    "                    tweet_row.append('update')\n",
    "                \n",
    "                    ### Extract station names\n",
    "                    ### =====================\n",
    "                    stn = re.search(re_stn, tweet_body.text)\n",
    "                    if extract:\n",
    "                        print (\"From: %s  To: %s\\n\" % (stn.group(1), stn.group(2)))  \n",
    "                        tweet_row.append(stn.group(1))   # from station\n",
    "                        tweet_row.append(stn.group(2))   # to station\n",
    "\n",
    "        else:    # if no mrt line mention in [xxx] format, then it is a normal information tweets.\n",
    "            tweet_row.append('None')\n",
    "            tweet_row.append('ok')\n",
    "            print('Status: OK')\n",
    "            print('Extracted tweet: %s\\n' % tweet_body.text)   # for checking only\n",
    "        \n",
    "        ### Store the extracted tweet info into the list container\n",
    "        smrt_tweet_data.append(tweet_row)\n",
    "        \n",
    "    except:\n",
    "        print(\"Extraction Error!\\n\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tabulate all the extracted data into table using panda\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(smrt_tweet_data, columns=['Tweet', 'Extracted Date/Time', 'Date/Time', 'MRT_Line', 'Status', 'From_Stn', 'To_Stn'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
